# Home_Sales
Module 22 Challenge

# Project Overview

This project involves using Apache Spark and SparkSQL to analyze home sales data, extracting key metrics and performing transformations.

## Tasks

1. Create a Spark DataFrame from the provided dataset.
2. Create a temporary table of the DataFrame.
3. Answer specific questions using SparkSQL queries.
4. Cache the temporary table and verify its caching status.
5. Run queries on the cached table and compare the runtime with uncached queries.
6. Partition the dataset by the "date_built" field and read the formatted parquet data.
7. Create a temporary table for the parquet data.
8. Run queries on the parquet temporary table and compare the runtime with previous queries.
9. Uncache the temporary table and verify its status.

## Files

- `Home_Sales_Code.ipynb`: Jupyter Notebook containing the SparkSQL code and analysis.
